{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "LinkPrediction.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyPg5OQAit+iFqRXcRzF3rfg",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/PinmanHuang/MLG/blob/master/LinkPrediction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T7AqBfMuBQxd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e-YzmWv-F5wE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "6cd495e6-4545-4f17-ba40-adc2364cb2bb"
      },
      "source": [
        "if torch.cuda.is_available():\n",
        "    device = torch.device(\"cuda:0\")\n",
        "    print(\"Running on the GPU\")\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"Running on the CPU\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Running on the GPU\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRbpMJVpHNCS",
        "colab_type": "text"
      },
      "source": [
        "# Upload and Read Data\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d8xXvVFEHNiK",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "4dddfb87-d0a4-4e7b-864a-f6265b0e59c8"
      },
      "source": [
        "# upload file into colab\n",
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-cc662b08-0106-4bbb-a399-9a51eeee8bea\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-cc662b08-0106-4bbb-a399-9a51eeee8bea\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving content.csv to content.csv\n",
            "Saving test.csv to test.csv\n",
            "Saving train.csv to train.csv\n",
            "Saving upload.csv to upload.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3y2FLFkqHTMo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# read upload csv\n",
        "\n",
        "# edge_id, to_node, from_node, node_attrs, edge_label\n",
        "import pandas as pd\n",
        "\n",
        "# attributes data\n",
        "data_attrs = pd.read_csv(\"content.csv\", sep='\\t', header=None, index_col = 0)\n",
        "data_attrs = data_attrs.sort_index(axis=0)  # sorting data in index\n",
        "node_attrs = torch.tensor(data_attrs.values)\n",
        "\n",
        "# train data\n",
        "data_train = pd.read_csv(\"train.csv\", sep=',')\n",
        "train_edge_id = data_train[['id']].values.tolist()\n",
        "train_to_node = data_train[['to']].values.tolist()\n",
        "train_from_node = data_train[['from']].values.tolist()\n",
        "train_edge_label = data_train[['label']].values.tolist()\n",
        "\n",
        "# test data\n",
        "data_test = pd.read_csv(\"test.csv\", sep=',')\n",
        "test_edge_id = data_train[['id']].values.tolist()\n",
        "test_to_node = data_train[['to']].values.tolist()\n",
        "test_from_node = data_train[['from']].values.tolist()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uoSg_X4aUTtp",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 284
        },
        "outputId": "588f0f8d-d5d9-42fd-fbf7-16ffa6f730bb"
      },
      "source": [
        "data_attrs.head(5)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>40</th>\n",
              "      <th>...</th>\n",
              "      <th>1394</th>\n",
              "      <th>1395</th>\n",
              "      <th>1396</th>\n",
              "      <th>1397</th>\n",
              "      <th>1398</th>\n",
              "      <th>1399</th>\n",
              "      <th>1400</th>\n",
              "      <th>1401</th>\n",
              "      <th>1402</th>\n",
              "      <th>1403</th>\n",
              "      <th>1404</th>\n",
              "      <th>1405</th>\n",
              "      <th>1406</th>\n",
              "      <th>1407</th>\n",
              "      <th>1408</th>\n",
              "      <th>1409</th>\n",
              "      <th>1410</th>\n",
              "      <th>1411</th>\n",
              "      <th>1412</th>\n",
              "      <th>1413</th>\n",
              "      <th>1414</th>\n",
              "      <th>1415</th>\n",
              "      <th>1416</th>\n",
              "      <th>1417</th>\n",
              "      <th>1418</th>\n",
              "      <th>1419</th>\n",
              "      <th>1420</th>\n",
              "      <th>1421</th>\n",
              "      <th>1422</th>\n",
              "      <th>1423</th>\n",
              "      <th>1424</th>\n",
              "      <th>1425</th>\n",
              "      <th>1426</th>\n",
              "      <th>1427</th>\n",
              "      <th>1428</th>\n",
              "      <th>1429</th>\n",
              "      <th>1430</th>\n",
              "      <th>1431</th>\n",
              "      <th>1432</th>\n",
              "      <th>1433</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1433 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "   1     2     3     4     5     6     ...  1428  1429  1430  1431  1432  1433\n",
              "0                                      ...                                    \n",
              "0     0     0     0     0     0     0  ...     0     0     0     0     0     0\n",
              "1     0     0     0     0     0     0  ...     0     0     0     0     0     0\n",
              "2     0     0     0     0     0     0  ...     0     0     0     0     0     0\n",
              "3     0     0     0     0     0     0  ...     0     0     0     0     1     0\n",
              "4     0     0     0     0     0     0  ...     0     0     0     0     0     0\n",
              "\n",
              "[5 rows x 1433 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ol_s0xQvULrq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0c147677-0ab0-4b7b-f091-1ec02fafe2a5"
      },
      "source": [
        "data_train.head(5)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>to</th>\n",
              "      <th>from</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>E10311</td>\n",
              "      <td>2399</td>\n",
              "      <td>2339</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E10255</td>\n",
              "      <td>2397</td>\n",
              "      <td>1144</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>E10667</td>\n",
              "      <td>854</td>\n",
              "      <td>1726</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>E9395</td>\n",
              "      <td>872</td>\n",
              "      <td>702</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>E5926</td>\n",
              "      <td>2450</td>\n",
              "      <td>1312</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id    to  from  label\n",
              "0  E10311  2399  2339      0\n",
              "1  E10255  2397  1144      1\n",
              "2  E10667   854  1726      0\n",
              "3   E9395   872   702      0\n",
              "4   E5926  2450  1312      1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-U7O0DXJ4xjx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "ddc399ee-6274-4c7d-de31-c3fef7023a9e"
      },
      "source": [
        "data_test.head(5)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>to</th>\n",
              "      <th>from</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>E10559</td>\n",
              "      <td>2323</td>\n",
              "      <td>2673</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>E4849</td>\n",
              "      <td>81</td>\n",
              "      <td>1634</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>E3964</td>\n",
              "      <td>2405</td>\n",
              "      <td>1765</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>E542</td>\n",
              "      <td>2114</td>\n",
              "      <td>498</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>E331</td>\n",
              "      <td>1013</td>\n",
              "      <td>849</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "       id    to  from\n",
              "0  E10559  2323  2673\n",
              "1   E4849    81  1634\n",
              "2   E3964  2405  1765\n",
              "3    E542  2114   498\n",
              "4    E331  1013   849"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hQshnvKhVfpi",
        "colab_type": "text"
      },
      "source": [
        "# Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jNgv1INyVbY8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create training X\n",
        "X = torch.zeros([len(train_edge_id), node_attrs.size()[1]*2], dtype=torch.long)\n",
        "for f_node, t_node, i in zip(train_from_node, train_to_node, range(len(train_edge_id))):\n",
        "    X[i] = torch.cat((node_attrs[f_node], node_attrs[t_node]), dim=1)\n",
        "\n",
        "# create training Y\n",
        "Y = torch.zeros([len(train_edge_id), 1], dtype=torch.float32)\n",
        "for label, i in zip(train_edge_label, range(len(train_edge_id))):\n",
        "    Y[i][0] = label[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PXYivNGlAn6h",
        "colab_type": "text"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Azh4zhtt9GOf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Net(torch.nn.Module):\n",
        "    def __init__(self, D_in = 2866, E = 1, H_sizes = [2048, 2048, 1024, 64, 32, 8], D_out = 1):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.D_in = D_in\n",
        "        self.E = E\n",
        "        self.H_sizes = H_sizes\n",
        "        self.D_out = D_out\n",
        "\n",
        "        self.embedding = torch.nn.Embedding(self.D_in, self.E)\n",
        "        self.fc1 = torch.nn.Linear(self.D_in, self.H_sizes[0], bias=True)\n",
        "        self.hidden = torch.nn.ModuleList()\n",
        "        for i in range(len(self.H_sizes)-1):\n",
        "            self.hidden.append(torch.nn.Linear(self.H_sizes[i], self.H_sizes[i+1], bias=True))\n",
        "        self.fc2 = torch.nn.Linear(self.H_sizes[-1], self.D_out, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x_emd = self.embedding(x)\n",
        "        x_emd = torch.squeeze(x_emd, 2)\n",
        "        h1 = self.fc1(x_emd)\n",
        "        h = torch.sigmoid(h1)\n",
        "        for layer in self.hidden:\n",
        "            h = layer(h)\n",
        "            h = torch.sigmoid(h)\n",
        "        h2 = self.fc2(h)\n",
        "        y_pre = torch.sigmoid(h2)\n",
        "        return y_pre"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pdyE9nfGpZVV",
        "colab_type": "text"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SSPf3ZpumPlN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Training Parameters\n",
        "EPOCHS = 100\n",
        "LEARNING_RATE = 0.002"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1YbQi9t9pdWe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "0c0434e0-6224-433b-c600-c8b49de03066"
      },
      "source": [
        "# parameters\n",
        "D_in = 2866\n",
        "E = 1\n",
        "H_sizes = [4096, 8192, 4096, 2048, 1024, 64, 32, 16, 8]\n",
        "D_out = 1\n",
        "# model = Net()\n",
        "model = Net(D_in, E, H_sizes, D_out).to(device)\n",
        "print(model)\n",
        "\n",
        "# optimizer\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=LEARNING_RATE)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (embedding): Embedding(2866, 1)\n",
            "  (fc1): Linear(in_features=2866, out_features=4096, bias=True)\n",
            "  (hidden): ModuleList(\n",
            "    (0): Linear(in_features=4096, out_features=8192, bias=True)\n",
            "    (1): Linear(in_features=8192, out_features=4096, bias=True)\n",
            "    (2): Linear(in_features=4096, out_features=2048, bias=True)\n",
            "    (3): Linear(in_features=2048, out_features=1024, bias=True)\n",
            "    (4): Linear(in_features=1024, out_features=64, bias=True)\n",
            "    (5): Linear(in_features=64, out_features=32, bias=True)\n",
            "    (6): Linear(in_features=32, out_features=16, bias=True)\n",
            "    (7): Linear(in_features=16, out_features=8, bias=True)\n",
            "  )\n",
            "  (fc2): Linear(in_features=8, out_features=1, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mTemlnzKp4LS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "af7dcd05-77f2-40f5-d71c-ff9f56798890"
      },
      "source": [
        "# X = X-0.5\n",
        "X = X.to(device)\n",
        "Y = Y.to(device)\n",
        "for i in range(EPOCHS):\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "\n",
        "    y_pred = model(X)\n",
        "    loss = torch.nn.functional.binary_cross_entropy(y_pred, Y)\n",
        "    print(\"EPOCH #{}'s loss: {}\".format(i+1, loss))\n",
        "    loss.backward()\n",
        "    optimizer.step()"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH #1's loss: 0.7053122520446777\n",
            "EPOCH #2's loss: 0.7035725116729736\n",
            "EPOCH #3's loss: 0.7021152973175049\n",
            "EPOCH #4's loss: 0.7008042931556702\n",
            "EPOCH #5's loss: 0.6996092796325684\n",
            "EPOCH #6's loss: 0.6985250115394592\n",
            "EPOCH #7's loss: 0.6975499987602234\n",
            "EPOCH #8's loss: 0.6966829895973206\n",
            "EPOCH #9's loss: 0.6959220170974731\n",
            "EPOCH #10's loss: 0.695264458656311\n",
            "EPOCH #11's loss: 0.6947067379951477\n",
            "EPOCH #12's loss: 0.6942448616027832\n",
            "EPOCH #13's loss: 0.6938745379447937\n",
            "EPOCH #14's loss: 0.6935890913009644\n",
            "EPOCH #15's loss: 0.6933819055557251\n",
            "EPOCH #16's loss: 0.6932440996170044\n",
            "EPOCH #17's loss: 0.6931663155555725\n",
            "EPOCH #18's loss: 0.6931381821632385\n",
            "EPOCH #19's loss: 0.6931493878364563\n",
            "EPOCH #20's loss: 0.6931890845298767\n",
            "EPOCH #21's loss: 0.6932473182678223\n",
            "EPOCH #22's loss: 0.6933143734931946\n",
            "EPOCH #23's loss: 0.6933819055557251\n",
            "EPOCH #24's loss: 0.6934436559677124\n",
            "EPOCH #25's loss: 0.6934942007064819\n",
            "EPOCH #26's loss: 0.6935302019119263\n",
            "EPOCH #27's loss: 0.6935506463050842\n",
            "EPOCH #28's loss: 0.6935550570487976\n",
            "EPOCH #29's loss: 0.6935448050498962\n",
            "EPOCH #30's loss: 0.6935217380523682\n",
            "EPOCH #31's loss: 0.6934884786605835\n",
            "EPOCH #32's loss: 0.6934479475021362\n",
            "EPOCH #33's loss: 0.693403422832489\n",
            "EPOCH #34's loss: 0.6933574080467224\n",
            "EPOCH #35's loss: 0.6933125853538513\n",
            "EPOCH #36's loss: 0.6932708621025085\n",
            "EPOCH #37's loss: 0.6932337880134583\n",
            "EPOCH #38's loss: 0.6932026743888855\n",
            "EPOCH #39's loss: 0.6931778788566589\n",
            "EPOCH #40's loss: 0.6931592226028442\n",
            "EPOCH #41's loss: 0.6931469440460205\n",
            "EPOCH #42's loss: 0.6931401491165161\n",
            "EPOCH #43's loss: 0.6931377053260803\n",
            "EPOCH #44's loss: 0.6931388974189758\n",
            "EPOCH #45's loss: 0.693142831325531\n",
            "EPOCH #46's loss: 0.6931482553482056\n",
            "EPOCH #47's loss: 0.6931542754173279\n",
            "EPOCH #48's loss: 0.6931602954864502\n",
            "EPOCH #49's loss: 0.6931656002998352\n",
            "EPOCH #50's loss: 0.6931698322296143\n",
            "EPOCH #51's loss: 0.69317227602005\n",
            "EPOCH #52's loss: 0.6931735277175903\n",
            "EPOCH #53's loss: 0.6931730508804321\n",
            "EPOCH #54's loss: 0.6931712627410889\n",
            "EPOCH #55's loss: 0.6931684613227844\n",
            "EPOCH #56's loss: 0.6931647658348083\n",
            "EPOCH #57's loss: 0.6931605339050293\n",
            "EPOCH #58's loss: 0.6931562423706055\n",
            "EPOCH #59's loss: 0.6931518912315369\n",
            "EPOCH #60's loss: 0.6931480765342712\n",
            "EPOCH #61's loss: 0.693144679069519\n",
            "EPOCH #62's loss: 0.6931418776512146\n",
            "EPOCH #63's loss: 0.693139910697937\n",
            "EPOCH #64's loss: 0.6931384205818176\n",
            "EPOCH #65's loss: 0.6931377649307251\n",
            "EPOCH #66's loss: 0.6931376457214355\n",
            "EPOCH #67's loss: 0.6931378245353699\n",
            "EPOCH #68's loss: 0.6931383609771729\n",
            "EPOCH #69's loss: 0.6931388974189758\n",
            "EPOCH #70's loss: 0.6931397318840027\n",
            "EPOCH #71's loss: 0.69314044713974\n",
            "EPOCH #72's loss: 0.6931409239768982\n",
            "EPOCH #73's loss: 0.6931414008140564\n",
            "EPOCH #74's loss: 0.6931414008140564\n",
            "EPOCH #75's loss: 0.6931414008140564\n",
            "EPOCH #76's loss: 0.6931412816047668\n",
            "EPOCH #77's loss: 0.6931409239768982\n",
            "EPOCH #78's loss: 0.69314044713974\n",
            "EPOCH #79's loss: 0.693139910697937\n",
            "EPOCH #80's loss: 0.693139374256134\n",
            "EPOCH #81's loss: 0.693138837814331\n",
            "EPOCH #82's loss: 0.6931383609771729\n",
            "EPOCH #83's loss: 0.693138062953949\n",
            "EPOCH #84's loss: 0.6931378841400146\n",
            "EPOCH #85's loss: 0.6931377053260803\n",
            "EPOCH #86's loss: 0.6931376457214355\n",
            "EPOCH #87's loss: 0.6931375861167908\n",
            "EPOCH #88's loss: 0.6931376457214355\n",
            "EPOCH #89's loss: 0.6931377053260803\n",
            "EPOCH #90's loss: 0.6931378245353699\n",
            "EPOCH #91's loss: 0.6931379437446594\n",
            "EPOCH #92's loss: 0.693138062953949\n",
            "EPOCH #93's loss: 0.6931381225585938\n",
            "EPOCH #94's loss: 0.6931382417678833\n",
            "EPOCH #95's loss: 0.6931381225585938\n",
            "EPOCH #96's loss: 0.693138062953949\n",
            "EPOCH #97's loss: 0.693138062953949\n",
            "EPOCH #98's loss: 0.6931379437446594\n",
            "EPOCH #99's loss: 0.6931379437446594\n",
            "EPOCH #100's loss: 0.6931377649307251\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMlkuJidDeWV",
        "colab_type": "text"
      },
      "source": [
        "## Batch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dJPAR-Yw0_km",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.utils.data as Data\n",
        "BATCH_SIZE = 4096\n",
        "torch_dataset = Data.TensorDataset(X, Y)\n",
        "loader = Data.DataLoader(\n",
        "    dataset=torch_dataset,\n",
        "    batch_size=BATCH_SIZE,\n",
        "    shuffle=False,\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0jnUK9GS2tb4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2fe2416b-6d41-4f64-dbfd-ff3af65a77c5"
      },
      "source": [
        "for i in range(EPOCHS):\n",
        "    \n",
        "    for step, (batch_x, batch_y) in enumerate(loader):\n",
        "        optimizer.zero_grad()\n",
        "        batch_x = batch_x.to(device)\n",
        "        batch_y = batch_y.to(device)\n",
        "\n",
        "        y_pred = model(batch_x)\n",
        "        loss = torch.nn.functional.binary_cross_entropy(y_pred, batch_y)\n",
        "        print(\"EPOCH #{}'s batch{} loss: {}\".format(i+1, step, loss))\n",
        "        loss.backward()\n",
        "        optimizer.step()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "EPOCH #1's batch0 loss: 0.6993962526321411\n",
            "EPOCH #1's batch1 loss: 0.6945520043373108\n",
            "EPOCH #1's batch2 loss: 0.6986106038093567\n",
            "EPOCH #2's batch0 loss: 0.6968657970428467\n",
            "EPOCH #2's batch1 loss: 0.6934847235679626\n",
            "EPOCH #2's batch2 loss: 0.696308434009552\n",
            "EPOCH #3's batch0 loss: 0.6950867176055908\n",
            "EPOCH #3's batch1 loss: 0.6929751038551331\n",
            "EPOCH #3's batch2 loss: 0.6945996284484863\n",
            "EPOCH #4's batch0 loss: 0.6938709616661072\n",
            "EPOCH #4's batch1 loss: 0.6929461359977722\n",
            "EPOCH #4's batch2 loss: 0.6934503316879272\n",
            "EPOCH #5's batch0 loss: 0.6931660175323486\n",
            "EPOCH #5's batch1 loss: 0.6932787895202637\n",
            "EPOCH #5's batch2 loss: 0.6927840113639832\n",
            "EPOCH #6's batch0 loss: 0.6928614974021912\n",
            "EPOCH #6's batch1 loss: 0.6937844753265381\n",
            "EPOCH #6's batch2 loss: 0.6924736499786377\n",
            "EPOCH #7's batch0 loss: 0.6927996873855591\n",
            "EPOCH #7's batch1 loss: 0.694252610206604\n",
            "EPOCH #7's batch2 loss: 0.6923658847808838\n",
            "EPOCH #8's batch0 loss: 0.6928251385688782\n",
            "EPOCH #8's batch1 loss: 0.6945315599441528\n",
            "EPOCH #8's batch2 loss: 0.6923406720161438\n",
            "EPOCH #9's batch0 loss: 0.6928431391716003\n",
            "EPOCH #9's batch1 loss: 0.6945778727531433\n",
            "EPOCH #9's batch2 loss: 0.6923427581787109\n",
            "EPOCH #10's batch0 loss: 0.6928303241729736\n",
            "EPOCH #10's batch1 loss: 0.6944398283958435\n",
            "EPOCH #10's batch2 loss: 0.6923660635948181\n",
            "EPOCH #11's batch0 loss: 0.6928074359893799\n",
            "EPOCH #11's batch1 loss: 0.6942036151885986\n",
            "EPOCH #11's batch2 loss: 0.6924203634262085\n",
            "EPOCH #12's batch0 loss: 0.6928001046180725\n",
            "EPOCH #12's batch1 loss: 0.6939492225646973\n",
            "EPOCH #12's batch2 loss: 0.6925069093704224\n",
            "EPOCH #13's batch0 loss: 0.6928201913833618\n",
            "EPOCH #13's batch1 loss: 0.6937288045883179\n",
            "EPOCH #13's batch2 loss: 0.6926116347312927\n",
            "EPOCH #14's batch0 loss: 0.6928605437278748\n",
            "EPOCH #14's batch1 loss: 0.6935648322105408\n",
            "EPOCH #14's batch2 loss: 0.6927117109298706\n",
            "EPOCH #15's batch0 loss: 0.6929046511650085\n",
            "EPOCH #15's batch1 loss: 0.6934598088264465\n",
            "EPOCH #15's batch2 loss: 0.6927861571311951\n",
            "EPOCH #16's batch0 loss: 0.6929374933242798\n",
            "EPOCH #16's batch1 loss: 0.6934064030647278\n",
            "EPOCH #16's batch2 loss: 0.692823588848114\n",
            "EPOCH #17's batch0 loss: 0.692950963973999\n",
            "EPOCH #17's batch1 loss: 0.6933943033218384\n",
            "EPOCH #17's batch2 loss: 0.6928240656852722\n",
            "EPOCH #18's batch0 loss: 0.6929453611373901\n",
            "EPOCH #18's batch1 loss: 0.6934142112731934\n",
            "EPOCH #18's batch2 loss: 0.6927967071533203\n",
            "EPOCH #19's batch0 loss: 0.6929270625114441\n",
            "EPOCH #19's batch1 loss: 0.6934561133384705\n",
            "EPOCH #19's batch2 loss: 0.6927540898323059\n",
            "EPOCH #20's batch0 loss: 0.6929038763046265\n",
            "EPOCH #20's batch1 loss: 0.693510115146637\n",
            "EPOCH #20's batch2 loss: 0.6927084922790527\n",
            "EPOCH #21's batch0 loss: 0.6928819417953491\n",
            "EPOCH #21's batch1 loss: 0.693565845489502\n",
            "EPOCH #21's batch2 loss: 0.6926683187484741\n",
            "EPOCH #22's batch0 loss: 0.6928650736808777\n",
            "EPOCH #22's batch1 loss: 0.6936140060424805\n",
            "EPOCH #22's batch2 loss: 0.6926386952400208\n",
            "EPOCH #23's batch0 loss: 0.6928537487983704\n",
            "EPOCH #23's batch1 loss: 0.6936478018760681\n",
            "EPOCH #23's batch2 loss: 0.692620575428009\n",
            "EPOCH #24's batch0 loss: 0.6928478479385376\n",
            "EPOCH #24's batch1 loss: 0.6936644911766052\n",
            "EPOCH #24's batch2 loss: 0.6926138401031494\n",
            "EPOCH #25's batch0 loss: 0.6928463578224182\n",
            "EPOCH #25's batch1 loss: 0.6936653852462769\n",
            "EPOCH #25's batch2 loss: 0.6926162242889404\n",
            "EPOCH #26's batch0 loss: 0.6928484439849854\n",
            "EPOCH #26's batch1 loss: 0.6936542987823486\n",
            "EPOCH #26's batch2 loss: 0.692625105381012\n",
            "EPOCH #27's batch0 loss: 0.692852795124054\n",
            "EPOCH #27's batch1 loss: 0.6936361789703369\n",
            "EPOCH #27's batch2 loss: 0.6926375031471252\n",
            "EPOCH #28's batch0 loss: 0.692858099937439\n",
            "EPOCH #28's batch1 loss: 0.693616509437561\n",
            "EPOCH #28's batch2 loss: 0.6926503777503967\n",
            "EPOCH #29's batch0 loss: 0.6928637027740479\n",
            "EPOCH #29's batch1 loss: 0.6935990452766418\n",
            "EPOCH #29's batch2 loss: 0.6926615238189697\n",
            "EPOCH #30's batch0 loss: 0.6928682327270508\n",
            "EPOCH #30's batch1 loss: 0.6935861706733704\n",
            "EPOCH #30's batch2 loss: 0.6926693916320801\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}